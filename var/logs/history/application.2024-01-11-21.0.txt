21:09:29.075 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:09:29.103 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 46534 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:09:29.104 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:09:30.599 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:09:30.660 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 56 ms. Found 4 JPA repository interfaces.
21:09:31.306 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:09:31.311 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:09:31.312 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:09:31.312 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:09:31.357 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:09:31.357 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2200 ms
21:09:31.667 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:09:31.716 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:09:31.744 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:09:31.931 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:09:31.956 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:09:32.185 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:09:32.256 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:09:33.116 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:09:33.299 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:09:34.485 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:09:34.908 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:09:34.990 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:09:34.991 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:09:34.991 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:09:34.991 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:09:34.991 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:09:35.001 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@75c2a35, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@a9e31e8, org.springframework.security.web.context.SecurityContextHolderFilter@dcf495c, org.springframework.security.web.header.HeaderWriterFilter@25d73ca6, org.springframework.web.filter.CorsFilter@27c2f134, org.springframework.security.web.authentication.logout.LogoutFilter@6231bb88, com.github.senocak.security.JwtAuthenticationFilter@1220969, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@4d162d67, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7f3aa737, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@64bed8b2, org.springframework.security.web.session.SessionManagementFilter@294a150c, org.springframework.security.web.access.ExceptionTranslationFilter@7edab945, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@19bdfa3e]
21:09:35.164 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:09:35.823 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:09:35.835 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:09:35.836 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:09:35.836 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:09:35.850 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:09:35.905 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:09:35.905 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:09:35.905 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996575904
21:09:35.906 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:09:35.907 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:09:35.907 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:09:35.908 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:09:35.908 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:09:35.910 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:09:35.911 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:09:35.911 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996575910
21:09:35.911 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:09:35.912 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:09:35.913 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:09:35.913 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:09:35.913 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:09:35.918 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:09:35.918 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:09:35.933 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:09:35.933 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:09:35.933 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996575933
21:09:35.933 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:09:35.953 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 7.141 seconds (process running for 7.926)
21:09:35.960 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 7
21:09:36.115 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:09:36.116 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:09:36.116 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:09:36.118 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:09:36.118 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:09:36.121 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:09:36.121 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:09:36.248 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 19 milliseconds [/* insert for com.github.senocak.domain.User.roles */insert into user_roles (user_id,role_id) values (?,?)]
21:09:36.681 [kafka-producer-network-thread | producer-1] ERROR [bucketName: ] o.a.k.c.p.internals.ProducerBatch - Error executing user-provided callback on message for topic-partition 'bucket-create-request-0'
java.lang.NullPointerException: Parameter specified as non-null is null: method com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2, parameter exception
	at com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2(AbsKafkaProducer.kt)
	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1490)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:309)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.complete(ProducerBatch.java:219)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:720)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:691)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:617)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:604)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:604)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:883)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:594)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:586)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:343)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:246)
	at java.base/java.lang.Thread.run(Thread.java:833)
21:09:36.681 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"ff810287-b8a2-4d56-bae1-1bfed1618e60","createdTime":1704996576269}, timestamp=null)
21:09:36.717 [kafka-producer-network-thread | producer-1] ERROR [bucketName: ] o.a.k.c.p.internals.ProducerBatch - Error executing user-provided callback on message for topic-partition 'bucket-create-request-0'
java.lang.NullPointerException: Parameter specified as non-null is null: method com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2, parameter exception
	at com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2(AbsKafkaProducer.kt)
	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1490)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:309)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.complete(ProducerBatch.java:219)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:720)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:691)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:617)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:604)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:604)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:883)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:594)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:586)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:343)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:246)
	at java.base/java.lang.Thread.run(Thread.java:833)
21:09:36.718 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"e3d66447-6151-4ffb-9cfc-b1b543d509d4","createdTime":1704996576681}, timestamp=null)
21:09:36.730 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:09:36.809 [RMI TCP Connection(5)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:09:39.185 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=54, memberId='SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408-cae84539-351e-4ebb-a4dd-9703ce3e8f29', protocol='range'}
21:09:39.185 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=54, memberId='SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b-ba6668d0-1a3a-4688-b200-a2606bc05857', protocol='range'}
21:09:39.213 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 54: {SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b-ba6668d0-1a3a-4688-b200-a2606bc05857=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408-cae84539-351e-4ebb-a4dd-9703ce3e8f29=Assignment(partitions=[])}
21:09:39.242 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=54, memberId='SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408-cae84539-351e-4ebb-a4dd-9703ce3e8f29', protocol='range'}
21:09:39.242 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=54, memberId='SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b-ba6668d0-1a3a-4688-b200-a2606bc05857', protocol='range'}
21:09:39.243 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:09:39.243 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:09:39.243 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb7cac704-0ba8-46e6-b2bc-3dcf7eb02408, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:09:39.244 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:09:39.252 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8fa1afdc-bf6b-4245-8342-44976e92588b, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:10:09.610 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:10:09.611 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:10:13.464 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:10:13.486 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 46579 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:10:13.486 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:10:14.233 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:10:14.288 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 51 ms. Found 4 JPA repository interfaces.
21:10:14.741 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:10:14.745 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:10:14.745 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:10:14.745 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:10:14.778 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:10:14.778 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1270 ms
21:10:14.970 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:10:15.003 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:10:15.021 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:10:15.151 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:10:15.166 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:10:15.278 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:10:15.330 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:10:15.830 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:10:15.909 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:10:16.550 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:10:16.823 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:10:16.874 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:10:16.874 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:10:16.874 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:10:16.874 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:10:16.874 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:10:16.881 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@49442e03, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@5bad04d1, org.springframework.security.web.context.SecurityContextHolderFilter@4d162d67, org.springframework.security.web.header.HeaderWriterFilter@3d2ec8b2, org.springframework.web.filter.CorsFilter@730c4dfd, org.springframework.security.web.authentication.logout.LogoutFilter@47c8c176, com.github.senocak.security.JwtAuthenticationFilter@6df8131c, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1428d63, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@1bb6bc81, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@736905fe, org.springframework.security.web.session.SessionManagementFilter@451f08ea, org.springframework.security.web.access.ExceptionTranslationFilter@5bf9bb2, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@39da0e47]
21:10:16.958 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:10:17.336 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:10:17.345 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:10:17.346 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:10:17.346 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:10:17.357 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:10:17.411 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:10:17.412 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:10:17.412 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996617411
21:10:17.413 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:10:17.414 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:10:17.414 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:10:17.414 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:10:17.414 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:10:17.416 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:10:17.418 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:10:17.418 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996617416
21:10:17.418 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:10:17.419 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:10:17.419 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:10:17.419 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:10:17.420 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:10:17.423 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:10:17.423 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:10:17.432 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:10:17.432 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:10:17.432 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996617431
21:10:17.432 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:10:17.444 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 4.178 seconds (process running for 4.879)
21:10:17.448 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 4
21:10:17.569 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:10:17.570 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:10:17.570 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:10:17.570 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:10:17.570 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:10:17.574 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:10:17.574 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:10:21.322 [kafka-producer-network-thread | producer-1] ERROR [bucketName: ] o.a.k.c.p.internals.ProducerBatch - Error executing user-provided callback on message for topic-partition 'bucket-create-request-0'
java.lang.NullPointerException: Parameter specified as non-null is null: method com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2, parameter exception
	at com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2(AbsKafkaProducer.kt)
	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1490)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:309)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.complete(ProducerBatch.java:219)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:720)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:691)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:617)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:604)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:604)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:883)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:594)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:586)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:343)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:246)
	at java.base/java.lang.Thread.run(Thread.java:833)
21:10:21.333 [kafka-producer-network-thread | producer-1] ERROR [bucketName: ] o.a.k.c.p.internals.ProducerBatch - Error executing user-provided callback on message for topic-partition 'bucket-create-request-0'
java.lang.NullPointerException: Parameter specified as non-null is null: method com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2, parameter exception
	at com.github.senocak.kafka.producer.AbsKafkaProducer.produce$lambda$2(AbsKafkaProducer.kt)
	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1490)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:309)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.complete(ProducerBatch.java:219)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:720)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:691)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:617)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:604)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:604)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:883)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:594)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:586)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:343)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:246)
	at java.base/java.lang.Thread.run(Thread.java:833)
21:10:21.374 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 23 milliseconds [/* insert for com.github.senocak.domain.Document */insert into documents (author,content_type,created_at,created_on,description,file_name,file_size,is_encrypted,keywords,number_of_pages,subject,updated_at,updated_on,user_id,id) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)]
21:10:21.391 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:10:22.264 [RMI TCP Connection(3)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:10:54.854 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=55, memberId='SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6-99bc9390-b21a-4205-bedb-771b16e155e6', protocol='range'}
21:10:54.854 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=55, memberId='SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53-074fb382-2ada-4caa-8daa-9aa22dd947dd', protocol='range'}
21:10:54.898 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 55: {SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6-99bc9390-b21a-4205-bedb-771b16e155e6=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53-074fb382-2ada-4caa-8daa-9aa22dd947dd=Assignment(partitions=[])}
21:10:54.913 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=55, memberId='SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6-99bc9390-b21a-4205-bedb-771b16e155e6', protocol='range'}
21:10:54.914 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=55, memberId='SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53-074fb382-2ada-4caa-8daa-9aa22dd947dd', protocol='range'}
21:10:54.916 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:10:54.916 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator6488b2df-1f49-40c8-8150-83639801dd53, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:10:54.917 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:10:54.919 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:10:54.947 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator109abde6-c8fd-481b-b15b-6fd7741c3dd6, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:11:04.068 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:11:04.069 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:11:07.723 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:11:07.752 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 46629 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:11:07.752 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:11:08.726 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:11:08.826 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 95 ms. Found 4 JPA repository interfaces.
21:11:09.417 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:11:09.423 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:11:09.425 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:11:09.425 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:11:09.464 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:11:09.464 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1678 ms
21:11:09.785 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:11:09.856 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:11:09.877 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:11:10.056 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:11:10.094 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:11:10.351 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:11:10.425 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:11:11.041 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:11:11.168 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:11:12.194 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:11:12.665 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:11:12.795 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:11:12.796 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:11:12.796 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:11:12.796 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:11:12.796 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:11:12.814 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@4bcff08c, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@52a1d6f, org.springframework.security.web.context.SecurityContextHolderFilter@3b68a50c, org.springframework.security.web.header.HeaderWriterFilter@545bc8e1, org.springframework.web.filter.CorsFilter@38bb297, org.springframework.security.web.authentication.logout.LogoutFilter@1a177f2c, com.github.senocak.security.JwtAuthenticationFilter@2fedf25b, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@5f51f320, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@56034552, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@6c96e1d5, org.springframework.security.web.session.SessionManagementFilter@5bf9bb2, org.springframework.security.web.access.ExceptionTranslationFilter@5b7b5484, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@5c658163]
21:11:12.953 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:11:13.808 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:11:13.833 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:11:13.835 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:11:13.836 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:11:13.860 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:11:13.937 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:11:13.937 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:11:13.937 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996673936
21:11:13.938 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:11:13.941 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:11:13.942 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:11:13.942 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:11:13.944 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:11:13.945 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:11:13.945 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:11:13.945 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996673945
21:11:13.945 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:11:13.950 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:11:13.952 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:11:13.952 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:11:13.953 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:11:13.956 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:11:13.956 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:11:13.972 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:11:13.972 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:11:13.972 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996673972
21:11:13.972 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:11:13.999 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 6.482 seconds (process running for 7.063)
21:11:14.005 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 6
21:11:14.158 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 16 milliseconds [/* <criteria> */ select r1_0.id,r1_0.created_at,r1_0.name,r1_0.updated_at from roles r1_0]
21:11:14.223 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:11:14.223 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:11:14.225 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:11:14.232 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:11:14.232 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:11:14.236 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:11:14.237 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:11:17.708 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"d13d9518-fe58-4e73-9b20-693945b43772","createdTime":1704996674406}, timestamp=null)
21:11:17.713 [RMI TCP Connection(10)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:11:17.746 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"1d79068f-2870-47d9-808e-1ce251a5249c","createdTime":1704996677708}, timestamp=null)
21:11:17.796 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 13 milliseconds [/* insert for com.github.senocak.domain.Document */insert into documents (author,content_type,created_at,created_on,description,file_name,file_size,is_encrypted,keywords,number_of_pages,subject,updated_at,updated_on,user_id,id) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)]
21:11:17.818 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:11:49.280 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=56, memberId='SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96-a494a8e9-b698-44be-b080-b1a29f6e0d78', protocol='range'}
21:11:49.280 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=56, memberId='SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c-a1a2dc2f-c72e-46f5-9568-57c91d5ca996', protocol='range'}
21:11:49.301 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 56: {SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96-a494a8e9-b698-44be-b080-b1a29f6e0d78=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c-a1a2dc2f-c72e-46f5-9568-57c91d5ca996=Assignment(partitions=[])}
21:11:49.342 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=56, memberId='SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c-a1a2dc2f-c72e-46f5-9568-57c91d5ca996', protocol='range'}
21:11:49.342 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=56, memberId='SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96-a494a8e9-b698-44be-b080-b1a29f6e0d78', protocol='range'}
21:11:49.342 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:11:49.342 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:11:49.343 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator20e99605-4fa9-4e94-92eb-d7d3380e875c, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:11:49.345 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:11:49.354 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator1ebfbebe-1cb7-4c08-8843-83a43c6cfe96, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:14:17.721 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:14:17.725 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:14:20.039 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:14:20.083 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 46833 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:14:20.085 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:14:21.414 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:14:21.465 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 47 ms. Found 4 JPA repository interfaces.
21:14:22.081 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:14:22.086 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:14:22.087 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:14:22.087 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:14:22.143 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:14:22.143 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2003 ms
21:14:22.448 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:14:22.484 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:14:22.506 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:14:22.662 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:14:22.684 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:14:22.804 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:14:22.854 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:14:23.454 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:14:23.589 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:14:24.328 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:14:24.601 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:14:24.658 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:14:24.658 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:14:24.658 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:14:24.658 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:14:24.658 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:14:24.666 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@5c943847, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@352b5f3c, org.springframework.security.web.context.SecurityContextHolderFilter@1d77762f, org.springframework.security.web.header.HeaderWriterFilter@6050d04d, org.springframework.web.filter.CorsFilter@24305eca, org.springframework.security.web.authentication.logout.LogoutFilter@5572be5a, com.github.senocak.security.JwtAuthenticationFilter@504ccf42, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@dc9033f, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5d81b90a, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5ca9a6a8, org.springframework.security.web.session.SessionManagementFilter@46092840, org.springframework.security.web.access.ExceptionTranslationFilter@60e83cb9, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@4a77d2a5]
21:14:24.743 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:14:25.175 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:14:25.186 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:14:25.187 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:14:25.187 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:14:25.199 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:14:25.257 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:14:25.258 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:14:25.258 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996865257
21:14:25.259 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:14:25.260 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:14:25.260 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:14:25.260 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:14:25.260 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:14:25.262 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:14:25.263 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:14:25.263 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996865262
21:14:25.264 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:14:25.265 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:14:25.265 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:14:25.265 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:14:25.265 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:14:25.269 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:14:25.269 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:14:25.281 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:14:25.281 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:14:25.281 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704996865281
21:14:25.281 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:14:25.293 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.475 seconds (process running for 6.135)
21:14:25.298 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:14:25.391 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 25 milliseconds [/* <criteria> */ select r1_0.id,r1_0.created_at,r1_0.name,r1_0.updated_at from roles r1_0]
21:14:25.434 [RMI TCP Connection(7)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:14:25.439 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:14:25.439 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:14:25.439 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:14:25.443 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:14:25.443 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:14:25.447 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:14:25.447 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:14:25.588 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 21 milliseconds [/* insert for com.github.senocak.domain.User.roles */insert into user_roles (user_id,role_id) values (?,?)]
21:14:25.685 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"8fdb8a29-94fd-4dc5-9103-60a7ee0c3cfe","createdTime":1704996865601}, timestamp=null)
21:14:25.697 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"b7783012-c634-4037-9e3c-dd50c6ef36a5","createdTime":1704996865684}, timestamp=null)
21:14:25.703 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:15:02.904 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=57, memberId='SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a-aded7ae5-6203-4cb6-b53a-a9eed4bb1e82', protocol='range'}
21:15:02.904 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=57, memberId='SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59-bd774d26-a687-4f59-91a6-2c60dcb4c3f6', protocol='range'}
21:15:02.918 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 57: {SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59-bd774d26-a687-4f59-91a6-2c60dcb4c3f6=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a-aded7ae5-6203-4cb6-b53a-a9eed4bb1e82=Assignment(partitions=[])}
21:15:02.929 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=57, memberId='SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59-bd774d26-a687-4f59-91a6-2c60dcb4c3f6', protocol='range'}
21:15:02.929 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:15:02.929 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=57, memberId='SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a-aded7ae5-6203-4cb6-b53a-a9eed4bb1e82', protocol='range'}
21:15:02.929 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:15:02.929 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:15:02.931 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:15:02.939 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:23:25.506 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.apache.kafka.clients.NetworkClient - [Consumer instanceId=SchedulerCoordinator7db6cd2e-7bf6-4b40-9026-b7f765b6ad59, clientId=AuthServer, groupId=AuthServer] Node -1 disconnected.
21:23:25.506 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -1 disconnected.
21:23:25.506 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.apache.kafka.clients.NetworkClient - [Consumer instanceId=SchedulerCoordinatorce857f14-0da0-42d6-940a-14f0486bd96a, clientId=AuthServer, groupId=AuthServer] Node -1 disconnected.
21:27:30.891 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997629258} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 0
                    
21:27:30.893 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 1 milliseconds
21:27:30.894 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997650760} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 1
                    
21:27:30.894 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:27:30.942 [pool-2-thread-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-2
21:27:30.942 [pool-2-thread-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-1
21:28:39.253 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:28:39.255 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:28:42.997 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:28:43.038 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 47406 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:28:43.039 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:28:43.964 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:28:44.016 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 47 ms. Found 4 JPA repository interfaces.
21:28:44.629 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:28:44.634 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:28:44.635 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:28:44.635 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:28:44.681 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:28:44.682 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1594 ms
21:28:44.996 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:28:45.042 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:28:45.070 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:28:45.221 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:28:45.239 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:28:45.490 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:28:45.590 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:28:46.418 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:28:46.668 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:28:47.536 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:28:47.862 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:28:47.942 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:28:47.943 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:28:47.943 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:28:47.943 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:28:47.943 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:28:47.952 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@3e6a55fb, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1b25ebea, org.springframework.security.web.context.SecurityContextHolderFilter@53785d1a, org.springframework.security.web.header.HeaderWriterFilter@60e83cb9, org.springframework.web.filter.CorsFilter@7aead7d9, org.springframework.security.web.authentication.logout.LogoutFilter@3a0afe5b, com.github.senocak.security.JwtAuthenticationFilter@2296ed0d, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@3a1eb893, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7e2bd635, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@605790e5, org.springframework.security.web.session.SessionManagementFilter@7cd50c3d, org.springframework.security.web.access.ExceptionTranslationFilter@6f77917c, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@3f02dc34]
21:28:48.038 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:28:48.505 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:28:48.517 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:28:48.518 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:28:48.518 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:28:48.532 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:28:48.601 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:28:48.601 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:28:48.601 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997728600
21:28:48.602 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:28:48.605 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:28:48.605 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:28:48.605 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:28:48.605 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:28:48.607 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:28:48.608 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:28:48.608 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997728607
21:28:48.608 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:28:48.610 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:28:48.610 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:28:48.610 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:28:48.611 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:28:48.615 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:28:48.615 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:28:48.623 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:28:48.623 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:28:48.623 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997728623
21:28:48.623 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:28:48.637 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.872 seconds (process running for 6.622)
21:28:48.646 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:28:48.776 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 18 milliseconds [/* <criteria> */ select r1_0.id,r1_0.created_at,r1_0.name,r1_0.updated_at from roles r1_0]
21:28:48.900 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:28:48.901 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:28:48.901 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:28:48.903 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:28:48.903 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:28:48.910 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:28:48.915 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:28:49.240 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"964f368a-5b13-4cd3-b23f-87fff7b147f4","createdTime":1704997729082}, timestamp=null)
21:28:49.254 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"b176bf01-8ff4-4571-a2e0-0ac1ec2d88b5","createdTime":1704997729239}, timestamp=null)
21:28:49.264 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:28:49.274 [RMI TCP Connection(11)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:29:24.429 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=58, memberId='SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087-db7e3bd3-7fc1-4a46-94da-66c5008db5e1', protocol='range'}
21:29:24.431 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=58, memberId='SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb-d1b6ae1d-5e6c-4155-befa-8842fd501563', protocol='range'}
21:29:24.444 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 58: {SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087-db7e3bd3-7fc1-4a46-94da-66c5008db5e1=Assignment(partitions=[]), SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb-d1b6ae1d-5e6c-4155-befa-8842fd501563=Assignment(partitions=[bucket-create-response-0])}
21:29:24.457 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=58, memberId='SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087-db7e3bd3-7fc1-4a46-94da-66c5008db5e1', protocol='range'}
21:29:24.457 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=58, memberId='SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb-d1b6ae1d-5e6c-4155-befa-8842fd501563', protocol='range'}
21:29:24.458 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:29:24.458 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:29:24.458 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8243a9ce-0831-40ca-97ec-716dcb196087, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:29:24.461 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:29:24.468 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator79edc121-19f0-495f-b67b-7a8842416dcb, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:29:24.521 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997737597} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 2
                    
21:29:24.522 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:29:24.523 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997737617} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 3
                    
21:29:24.523 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:29:24.552 [pool-2-thread-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-2
21:29:24.552 [pool-2-thread-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-1
21:30:47.486 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:30:47.487 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:30:50.291 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:30:50.316 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 47498 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:30:50.317 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:30:51.399 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:30:51.490 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 84 ms. Found 4 JPA repository interfaces.
21:30:52.187 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:30:52.194 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:30:52.196 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:30:52.196 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:30:52.238 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:30:52.239 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1896 ms
21:30:52.633 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:30:52.677 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:30:52.713 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:30:52.870 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:30:52.890 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:30:53.059 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:30:53.104 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:30:53.660 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:30:53.751 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:30:54.545 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:30:54.883 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:30:54.973 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:30:54.974 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:30:54.974 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:30:54.974 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:30:54.974 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:30:54.984 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@38300447, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@14484887, org.springframework.security.web.context.SecurityContextHolderFilter@ae2227, org.springframework.security.web.header.HeaderWriterFilter@2574123a, org.springframework.web.filter.CorsFilter@48c42253, org.springframework.security.web.authentication.logout.LogoutFilter@56aacc7b, com.github.senocak.security.JwtAuthenticationFilter@2ab0ca04, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7e2bd635, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@dc9033f, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@32647dde, org.springframework.security.web.session.SessionManagementFilter@649a76c1, org.springframework.security.web.access.ExceptionTranslationFilter@2338c3f9, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@420849f6]
21:30:55.095 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:30:55.613 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:30:55.628 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:30:55.629 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:30:55.629 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:30:55.646 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:30:55.714 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:30:55.714 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:30:55.714 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997855713
21:30:55.715 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:30:55.737 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:30:55.737 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:30:55.738 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:30:55.738 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:30:55.741 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:30:55.741 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:30:55.741 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997855741
21:30:55.742 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:20)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:30:55.743 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:30:55.743 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:30:55.744 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:30:55.744 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:30:55.748 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:30:55.748 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:30:55.756 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:30:55.757 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:30:55.757 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704997855756
21:30:55.757 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:30:55.769 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.658 seconds (process running for 6.295)
21:30:55.775 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:30:55.927 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 14 milliseconds [/* insert for com.github.senocak.domain.Role */insert into roles (created_at,name,updated_at,id) values (?,?,?,?)]
21:30:55.945 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:30:55.946 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:30:55.946 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:30:55.947 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:30:55.947 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:30:55.951 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:30:55.951 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:30:56.141 [RMI TCP Connection(11)-192.168.1.20] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
21:31:18.318 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"d14ad662-f48d-4c4e-836c-c33f6d9a9c5c","createdTime":1704997856158}, timestamp=null)
21:31:18.354 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"1bd46a55-03ef-478a-ae0a-fc453b2944b0","createdTime":1704997878317}, timestamp=null)
21:31:18.388 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:31:32.597 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=59, memberId='SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919-e1c82f35-0c2b-44d5-8737-c9d5dee110a5', protocol='range'}
21:31:32.600 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=59, memberId='SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3-6b50a0c0-3f6e-4a2d-9518-059d77c62886', protocol='range'}
21:31:32.620 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 59: {SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919-e1c82f35-0c2b-44d5-8737-c9d5dee110a5=Assignment(partitions=[]), SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3-6b50a0c0-3f6e-4a2d-9518-059d77c62886=Assignment(partitions=[bucket-create-response-0])}
21:31:32.647 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=59, memberId='SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919-e1c82f35-0c2b-44d5-8737-c9d5dee110a5', protocol='range'}
21:31:32.647 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=59, memberId='SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3-6b50a0c0-3f6e-4a2d-9518-059d77c62886', protocol='range'}
21:31:32.648 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:31:32.648 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:31:32.648 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator54522376-bd7f-4092-accb-69a1f2fe0919, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:31:32.651 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:31:32.660 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4b929f63-81cb-4994-9b52-5924d30392d3, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:31:32.704 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997856440} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 4
                    
21:31:32.705 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 1 milliseconds
21:31:32.706 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704997878381} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 5
                    
21:31:32.706 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:31:32.730 [pool-2-thread-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-1
21:31:32.730 [pool-2-thread-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-2
21:35:41.947 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:35:41.957 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:50:41.261 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:50:41.293 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 48347 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:50:41.294 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:50:42.292 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:50:42.364 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 66 ms. Found 4 JPA repository interfaces.
21:50:43.009 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:50:43.015 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:50:43.016 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:50:43.016 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:50:43.071 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:50:43.071 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1747 ms
21:50:43.307 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:50:43.348 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:50:43.373 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:50:43.516 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:50:43.535 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:50:43.715 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:50:43.762 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:50:44.485 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:50:44.571 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:50:45.307 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:50:45.591 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:50:45.650 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:50:45.650 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:50:45.650 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:50:45.650 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:50:45.651 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:50:45.659 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@76b49d0, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@223c42b0, org.springframework.security.web.context.SecurityContextHolderFilter@5d81b90a, org.springframework.security.web.header.HeaderWriterFilter@7d97a1a0, org.springframework.web.filter.CorsFilter@6acedf54, org.springframework.security.web.authentication.logout.LogoutFilter@717c00f9, com.github.senocak.security.JwtAuthenticationFilter@19cee7ed, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2aa143ba, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@21cb907d, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@2a0cc666, org.springframework.security.web.session.SessionManagementFilter@5c0bacaa, org.springframework.security.web.access.ExceptionTranslationFilter@6231bb88, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@38300447]
21:50:45.733 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:50:46.135 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:50:46.145 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:50:46.146 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:50:46.146 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:50:46.159 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:50:46.213 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:50:46.213 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:50:46.213 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999046212
21:50:46.214 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:50:46.221 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:50:46.221 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:50:46.221 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:50:46.221 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:50:46.223 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:50:46.223 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:50:46.223 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999046223
21:50:46.224 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:50:46.226 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:50:46.226 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:50:46.226 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:50:46.226 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:50:46.226 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:50:46.228 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:50:46.228 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:50:46.228 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999046228
21:50:46.228 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:50:46.229 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:50:46.229 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-3
21:50:46.229 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-3 is running for BucketCreateResponseConsumer
21:50:46.229 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:50:46.233 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:50:46.233 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:50:46.240 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:50:46.240 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:50:46.240 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999046240
21:50:46.240 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:50:46.256 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.223 seconds (process running for 10.802)
21:50:46.260 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:50:46.405 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:50:46.405 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:50:46.405 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:50:46.406 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:50:46.406 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:50:46.406 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:50:46.406 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:50:46.411 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:50:46.411 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:50:46.411 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:50:46.590 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"83e30e35-767c-46f6-b72e-2608a0d9d08f","createdTime":1704999046488}, timestamp=null)
21:50:46.624 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"a3f0be41-60c7-42bc-a6e3-18eef1ad97c1","createdTime":1704999046590}, timestamp=null)
21:50:46.638 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:50:49.469 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=61, memberId='SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f-c9f12267-21e4-40d0-9a1e-f3a1cda37491', protocol='range'}
21:50:49.469 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=61, memberId='SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8-0f54bbb6-d70b-46e3-8a43-7e2450243615', protocol='range'}
21:50:49.471 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=61, memberId='SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0-92623f2f-64f3-4c7b-8260-5625862d00d0', protocol='range'}
21:50:49.474 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 61: {SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f-c9f12267-21e4-40d0-9a1e-f3a1cda37491=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8-0f54bbb6-d70b-46e3-8a43-7e2450243615=Assignment(partitions=[]), SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0-92623f2f-64f3-4c7b-8260-5625862d00d0=Assignment(partitions=[])}
21:50:49.486 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=61, memberId='SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f-c9f12267-21e4-40d0-9a1e-f3a1cda37491', protocol='range'}
21:50:49.486 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:50:49.486 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=61, memberId='SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0-92623f2f-64f3-4c7b-8260-5625862d00d0', protocol='range'}
21:50:49.487 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=61, memberId='SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8-0f54bbb6-d70b-46e3-8a43-7e2450243615', protocol='range'}
21:50:49.487 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:50:49.487 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:50:49.487 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator8e082465-4c28-47a5-ac8a-2acb711a2af0, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:50:49.487 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator78756072-c5c8-4b47-99d8-819b12850aa8, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:50:49.488 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:50:49.495 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator5433aa02-8397-41c0-ac66-4485f2b61f6f, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:50:49.517 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999046638} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 6
                    
21:50:49.517 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:50:49.518 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999046662} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 7
                    
21:50:49.518 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Time taken: 0 milliseconds
21:50:49.541 [pool-2-thread-1] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-1
21:50:49.541 [pool-2-thread-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:pool-2-thread-2
21:51:08.202 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:51:08.204 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:51:23.591 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:51:23.616 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 48375 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:51:23.617 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:51:24.449 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:51:24.598 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 135 ms. Found 4 JPA repository interfaces.
21:51:25.146 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:51:25.152 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:51:25.154 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:51:25.154 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:51:25.198 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:51:25.199 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1558 ms
21:51:25.488 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:51:25.530 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:51:25.552 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:51:25.721 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:51:25.738 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:51:25.922 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:51:25.976 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:51:26.685 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:51:26.811 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:51:27.550 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:51:27.834 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:51:27.886 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:51:27.887 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:51:27.887 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:51:27.887 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:51:27.887 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:51:27.894 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@3e6a55fb, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1b25ebea, org.springframework.security.web.context.SecurityContextHolderFilter@53785d1a, org.springframework.security.web.header.HeaderWriterFilter@60e83cb9, org.springframework.web.filter.CorsFilter@7aead7d9, org.springframework.security.web.authentication.logout.LogoutFilter@3a0afe5b, com.github.senocak.security.JwtAuthenticationFilter@43b41cb9, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@3a1eb893, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7e2bd635, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@605790e5, org.springframework.security.web.session.SessionManagementFilter@7cd50c3d, org.springframework.security.web.access.ExceptionTranslationFilter@6f77917c, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@3f02dc34]
21:51:27.978 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:51:28.365 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:51:28.376 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:51:28.377 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:51:28.377 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:51:28.391 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:51:28.446 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:51:28.446 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:51:28.446 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999088445
21:51:28.447 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:51:28.448 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:51:28.448 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:51:28.448 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:51:28.448 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:51:28.450 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:51:28.450 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:51:28.450 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999088450
21:51:28.452 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:51:28.453 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:51:28.453 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:51:28.453 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:51:28.453 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:51:28.453 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:51:28.455 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:51:28.455 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:51:28.455 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999088455
21:51:28.455 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:51:28.455 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:51:28.456 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-3
21:51:28.456 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-3 is running for BucketCreateResponseConsumer
21:51:28.456 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:51:28.463 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:51:28.464 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:51:28.470 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:51:28.470 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:51:28.471 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999088470
21:51:28.471 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:51:28.483 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.069 seconds (process running for 10.688)
21:51:28.488 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:51:28.607 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 26 milliseconds [/* <criteria> */ select u1_0.id,u1_0.created_at,u1_0.email,u1_0.name,u1_0.password,u1_0.updated_at from users u1_0]
21:51:28.609 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:51:28.609 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:51:28.609 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:51:28.609 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:51:28.610 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:51:28.610 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:51:28.611 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:51:28.616 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:51:28.617 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:51:28.617 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:51:35.236 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"a78e04be-873b-4a4f-864a-a62d32aaf0f6","createdTime":1704999088766}, timestamp=null)
21:51:35.301 [pool-6-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"17e11005-d204-4602-a28f-c2db83c5cfcc","createdTime":1704999095237}, timestamp=null)
21:51:35.349 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 32 milliseconds [/* insert for com.github.senocak.domain.Document */insert into documents (author,content_type,created_at,created_on,description,file_name,file_size,is_encrypted,keywords,number_of_pages,subject,updated_at,updated_on,user_id,id) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)]
21:51:35.363 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:51:54.066 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=62, memberId='SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072-23819633-b02f-4774-aa41-b6da75ee1762', protocol='range'}
21:51:54.067 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=62, memberId='SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011-7175e205-850d-4158-a2a4-1f8aa835df60', protocol='range'}
21:51:54.066 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=62, memberId='SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1-b4148966-1451-4fbb-b8f0-79a5db2d32ef', protocol='range'}
21:51:54.102 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 62: {SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1-b4148966-1451-4fbb-b8f0-79a5db2d32ef=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011-7175e205-850d-4158-a2a4-1f8aa835df60=Assignment(partitions=[]), SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072-23819633-b02f-4774-aa41-b6da75ee1762=Assignment(partitions=[])}
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=62, memberId='SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011-7175e205-850d-4158-a2a4-1f8aa835df60', protocol='range'}
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=62, memberId='SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1-b4148966-1451-4fbb-b8f0-79a5db2d32ef', protocol='range'}
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=62, memberId='SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072-23819633-b02f-4774-aa41-b6da75ee1762', protocol='range'}
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:51:54.131 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:51:54.132 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator4acdc001-925b-4583-81af-7488fdfdf072, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:51:54.132 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator23f62f0c-4e31-42f1-85bd-2fbb6581c011, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:51:54.133 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:51:54.141 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator008ebbfe-e2b0-409d-ac4e-1d0db69d94b1, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:51:54.210 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999088879} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 8
                    
21:51:54.244 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:BucketCreateResponseConsumer-bucket-create-response-2
21:51:54.246 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999095310} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 9
                    
21:51:54.246 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:BucketCreateResponseConsumer-bucket-create-response-2
21:52:55.997 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:52:55.999 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:53:12.022 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:53:12.056 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 48455 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:53:12.057 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:53:13.569 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:53:13.656 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 81 ms. Found 4 JPA repository interfaces.
21:53:14.305 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:53:14.310 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:53:14.311 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:53:14.311 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:53:14.353 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:53:14.353 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2267 ms
21:53:14.589 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:53:14.624 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:53:14.644 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:53:14.787 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:53:14.803 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:53:14.976 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:53:15.068 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:53:15.782 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:53:15.912 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:53:16.864 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:53:17.155 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:53:17.212 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:53:17.213 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:53:17.213 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:53:17.213 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:53:17.213 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:53:17.220 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@ace45e9, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@5c943847, org.springframework.security.web.context.SecurityContextHolderFilter@52e296c0, org.springframework.security.web.header.HeaderWriterFilter@5891bd6d, org.springframework.web.filter.CorsFilter@352b5f3c, org.springframework.security.web.authentication.logout.LogoutFilter@423ddfe1, com.github.senocak.security.JwtAuthenticationFilter@64f55630, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7cb15360, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@1e7b277a, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@24305eca, org.springframework.security.web.session.SessionManagementFilter@42cf08a1, org.springframework.security.web.access.ExceptionTranslationFilter@1ee2e363, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@59a79420]
21:53:17.297 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:53:17.737 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:53:17.748 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:53:17.750 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:53:17.750 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:53:17.765 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:53:17.823 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:53:17.823 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:53:17.823 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999197822
21:53:17.824 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:53:17.826 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:53:17.826 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:53:17.826 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:53:17.826 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:53:17.828 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:53:17.828 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:53:17.828 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999197828
21:53:17.829 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:53:17.831 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:53:17.831 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:53:17.831 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer}
21:53:17.831 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:53:17.831 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:53:17.833 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:53:17.833 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:53:17.833 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999197833
21:53:17.833 [main] WARN  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=AuthServer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:772)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:652)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632)
	at com.github.senocak.kafka.consumer.AbstractKafkaConsumer.init(AbstractKafkaConsumer.kt:52)
	at com.github.senocak.kafka.consumer.BucketCreateResponseConsumer.start(BucketCreateResponseConsumer.kt:22)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:284)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:467)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:256)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:201)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:979)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:628)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:464)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:334)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1358)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1347)
	at com.github.senocak.AuthAppKt.main(AuthApp.kt:13)
21:53:17.833 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:53:17.833 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-3
21:53:17.833 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-3 is running for BucketCreateResponseConsumer
21:53:17.833 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:53:17.837 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:53:17.837 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:53:17.845 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:53:17.845 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:53:17.845 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999197845
21:53:17.845 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:53:17.859 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 6.058 seconds (process running for 12.435)
21:53:17.864 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 6
21:53:17.967 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 14 milliseconds [/* <criteria> */ select r1_0.id,r1_0.created_at,r1_0.name,r1_0.updated_at from roles r1_0]
21:53:17.991 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 11 milliseconds [/* <criteria> */ select u1_0.id,u1_0.created_at,u1_0.email,u1_0.name,u1_0.password,u1_0.updated_at from users u1_0]
21:53:18.044 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:53:18.044 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:53:18.045 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:53:18.045 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:53:18.045 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:53:18.045 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:53:18.045 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:53:18.051 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:53:18.052 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:53:18.052 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] (Re-)joining group
21:53:18.375 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"7554faa3-0fc0-4780-9e85-f5c05eaa31f6","createdTime":1704999198162}, timestamp=null)
21:53:18.388 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:53:41.482 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=63, memberId='SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd-e764626a-7593-4676-93ea-95ce010c72f8', protocol='range'}
21:53:41.480 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=63, memberId='SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f-b4deef7f-a94b-4aea-8c0a-d227123cca23', protocol='range'}
21:53:41.480 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Successfully joined group with generation Generation{generationId=63, memberId='SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71-dd311189-d8cd-459c-a923-d0b75fc15dde', protocol='range'}
21:53:41.512 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Finished assignment for group at generation 63: {SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f-b4deef7f-a94b-4aea-8c0a-d227123cca23=Assignment(partitions=[]), SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd-e764626a-7593-4676-93ea-95ce010c72f8=Assignment(partitions=[]), SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71-dd311189-d8cd-459c-a923-d0b75fc15dde=Assignment(partitions=[bucket-create-response-0])}
21:53:41.529 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=63, memberId='SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71-dd311189-d8cd-459c-a923-d0b75fc15dde', protocol='range'}
21:53:41.529 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=63, memberId='SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f-b4deef7f-a94b-4aea-8c0a-d227123cca23', protocol='range'}
21:53:41.529 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Successfully synced group in generation Generation{generationId=63, memberId='SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd-e764626a-7593-4676-93ea-95ce010c72f8', protocol='range'}
21:53:41.530 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:53:41.530 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:53:41.530 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:53:41.530 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorbdf6cc93-ae08-4e2e-9fd9-34281d94dc4f, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:53:41.530 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorf21c4045-09d2-4978-a22f-baa5c941b9cd, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: 
21:53:41.533 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:53:41.545 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinatorb6b487cb-95b6-43a0-bd1c-969d72001b71, clientId=AuthServer, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:53:41.610 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999198416} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 10
                    
21:53:41.684 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:BucketCreateResponseConsumer-bucket-create-response-2
21:56:05.365 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Shutting down: BucketCreateResponseConsumer
21:56:05.369 [SpringApplicationShutdownHook] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - Shutting down KafkaMsgConsumer for owner: BucketCreateResponseConsumer and threadNumber:1
21:56:12.880 [background-preinit] INFO  [bucketName: ] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
21:56:12.943 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Starting AuthAppKt using Java 17.0.8 with PID 48629 (/Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth/build/classes/kotlin/main started by tcasenocak in /Users/tcasenocak/Desktop/github/BookStore-Kotlin-Typescript/spring-kotlin-auth)
21:56:12.944 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - No active profile set, falling back to 1 default profile: "default"
21:56:14.203 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
21:56:14.351 [main] INFO  [bucketName: ] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 133 ms. Found 4 JPA repository interfaces.
21:56:14.943 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8081 (http)
21:56:14.948 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8081"]
21:56:14.949 [main] INFO  [bucketName: ] o.a.catalina.core.StandardService - Starting service [Tomcat]
21:56:14.950 [main] INFO  [bucketName: ] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.17]
21:56:14.992 [main] INFO  [bucketName: ] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
21:56:14.992 [main] INFO  [bucketName: ] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2018 ms
21:56:15.219 [main] INFO  [bucketName: ] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
21:56:15.263 [main] INFO  [bucketName: ] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.4.1.Final
21:56:15.288 [main] INFO  [bucketName: ] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
21:56:15.408 [main] INFO  [bucketName: ] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
21:56:15.423 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
21:56:15.542 [main] INFO  [bucketName: ] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
21:56:15.603 [main] WARN  [bucketName: ] org.hibernate.orm.deprecation - HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
21:56:16.183 [main] INFO  [bucketName: ] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
21:56:16.312 [main] INFO  [bucketName: ] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
21:56:17.204 [main] WARN  [bucketName: ] o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
21:56:17.592 [main] INFO  [bucketName: ] o.s.b.a.e.web.EndpointLinksResolver - Exposing 13 endpoint(s) beneath base path '/actuator'
21:56:17.653 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/auth/**']
21:56:17.654 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/api/v1/swagger/**']
21:56:17.654 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/actuator**/**']
21:56:17.654 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [permitAll] for Mvc [pattern='/swagger**/**']
21:56:17.654 [main] DEBUG [bucketName: ] o.s.s.w.a.e.ExpressionBasedFilterInvocationSecurityMetadataSource - Adding web access control expression [authenticated] for any request
21:56:17.664 [main] INFO  [bucketName: ] o.s.s.web.DefaultSecurityFilterChain - Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@fa3db48, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@19158d56, org.springframework.security.web.context.SecurityContextHolderFilter@5891bd6d, org.springframework.security.web.header.HeaderWriterFilter@796affb8, org.springframework.web.filter.CorsFilter@3f02dc34, org.springframework.security.web.authentication.logout.LogoutFilter@a885aa1, com.github.senocak.security.JwtAuthenticationFilter@245a90b1, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@6f014f27, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7cd50c3d, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@7f49fa1d, org.springframework.security.web.session.SessionManagementFilter@1cf45f46, org.springframework.security.web.access.ExceptionTranslationFilter@5e1d6ace, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@61ce2d47]
21:56:17.781 [main] INFO  [bucketName: ] c.g.s.c.AppConfig$$SpringCGLIB$$0 - Core pool size: 10, max pool size: 10000,keepAliveSeconds: 60, queueCapacity: -1,queueSize: 0
21:56:18.391 [main] INFO  [bucketName: ] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8081"]
21:56:18.415 [main] INFO  [bucketName: ] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8081 (http) with context path ''
21:56:18.417 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer Topic: bucket-create-response starting
21:56:18.418 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer-bucket-create-response-1}
21:56:18.440 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer-bucket-create-response-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:56:18.536 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:56:18.536 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:56:18.536 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999378534
21:56:18.538 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:56:18.552 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-1
21:56:18.553 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer-bucket-create-response-2}
21:56:18.553 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer-bucket-create-response-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:56:18.555 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-1 is running for BucketCreateResponseConsumer
21:56:18.557 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:56:18.557 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:56:18.557 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999378557
21:56:18.558 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:56:18.558 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-2
21:56:18.558 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Create Consumer Config >> Properties object:{key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.poll.records=1, group.instance.id=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, group.id=AuthServer, bootstrap.servers=localhost:9092, auto.commit.interval.ms=100, fetch.max.bytes=10485760, client.id=AuthServer-bucket-create-response-3}
21:56:18.558 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-2 is running for BucketCreateResponseConsumer
21:56:18.558 [main] INFO  [bucketName: ] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = AuthServer-bucket-create-response-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 10485760
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = AuthServer
	group.instance.id = SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

21:56:18.561 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:56:18.561 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:56:18.561 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999378561
21:56:18.562 [main] INFO  [bucketName: ] o.a.k.clients.consumer.KafkaConsumer - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Subscribed to topic(s): bucket-create-response
21:56:18.562 [main] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumer started for topic name:bucket-create-response with thread: BucketCreateResponseConsumer-bucket-create-response-3
21:56:18.562 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer - KafkaConsumer Thread-3 is running for BucketCreateResponseConsumer
21:56:18.562 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initializing KafkaProducer: Topic Name: bucket-create-request
21:56:18.568 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - Idempotence will be disabled because acks is set to 1, not set to 'all'.
21:56:18.568 [main] INFO  [bucketName: ] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

21:56:18.583 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.1
21:56:18.583 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:56:18.583 [main] INFO  [bucketName: ] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1704999378583
21:56:18.583 [main] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - initialized KafkaProducer: Topic Name: bucket-create-request
21:56:18.608 [main] INFO  [bucketName: ] com.github.senocak.AuthAppKt - Started AuthAppKt in 5.979 seconds (process running for 6.894)
21:56:18.617 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - Time: 5
21:56:18.840 [main] INFO  [bucketName: ] org.hibernate.SQL_SLOW - Slow query took 11 milliseconds [/* insert for com.github.senocak.domain.Role */insert into roles (created_at,name,updated_at,id) values (?,?,?,?)]
21:56:18.878 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:56:18.878 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:56:18.878 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:56:18.878 [kafka-producer-network-thread | producer-1] INFO  [bucketName: ] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: jXkXQ6ncQhuA24ujfMha2g
21:56:18.883 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:56:18.883 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:56:18.883 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
21:56:18.887 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] (Re-)joining group
21:56:18.887 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] (Re-)joining group
21:56:18.887 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] (Re-)joining group
21:56:19.184 [pool-5-thread-1] INFO  [bucketName: ] c.g.s.k.p.BucketCreateRequestKafkaProducer - Kafka message produced. message: ProducerRecord(topic=bucket-create-request, partition=null, headers=RecordHeaders(headers = [RecordHeader(key = from, value = [65, 117, 116, 104, 83, 101, 114, 118, 101, 114])], isReadOnly = true), key=AuthServer, value={"action":"MAKE_BUCKET","value":"372ae7d1-107f-40d1-9b1d-f1df5845935f","createdTime":1704999379035}, timestamp=null)
21:56:19.198 [main] INFO  [bucketName: ] com.github.senocak.domain.Listener - [ApplicationReadyEvent]: db migrated.
21:56:50.745 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Successfully joined group with generation Generation{generationId=64, memberId='SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7-a2b7f509-e801-4aba-999b-508aeb93a4d8', protocol='range'}
21:56:50.746 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Successfully joined group with generation Generation{generationId=64, memberId='SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b-5943d471-fe6f-4565-956c-d1279f780850', protocol='range'}
21:56:50.745 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Successfully joined group with generation Generation{generationId=64, memberId='SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291-347471c0-e1e0-4a3f-8e92-669bc2a9defc', protocol='range'}
21:56:50.782 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Finished assignment for group at generation 64: {SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291-347471c0-e1e0-4a3f-8e92-669bc2a9defc=Assignment(partitions=[bucket-create-response-0]), SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b-5943d471-fe6f-4565-956c-d1279f780850=Assignment(partitions=[]), SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7-a2b7f509-e801-4aba-999b-508aeb93a4d8=Assignment(partitions=[])}
21:56:50.812 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Successfully synced group in generation Generation{generationId=64, memberId='SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b-5943d471-fe6f-4565-956c-d1279f780850', protocol='range'}
21:56:50.812 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Successfully synced group in generation Generation{generationId=64, memberId='SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291-347471c0-e1e0-4a3f-8e92-669bc2a9defc', protocol='range'}
21:56:50.812 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Successfully synced group in generation Generation{generationId=64, memberId='SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7-a2b7f509-e801-4aba-999b-508aeb93a4d8', protocol='range'}
21:56:50.813 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:56:50.813 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[])
21:56:50.813 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Notifying assignor about the new Assignment(partitions=[bucket-create-response-0])
21:56:50.813 [BucketCreateResponseConsumer-bucket-create-response-1] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator797d868c-2634-4c00-a035-0acfb73a7fe7, clientId=AuthServer-bucket-create-response-1, groupId=AuthServer] Adding newly assigned partitions: 
21:56:50.813 [BucketCreateResponseConsumer-bucket-create-response-2] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator2f7609b4-244a-47ab-9411-e89a8dc6a51b, clientId=AuthServer-bucket-create-response-2, groupId=AuthServer] Adding newly assigned partitions: 
21:56:50.816 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Adding newly assigned partitions: bucket-create-response-0
21:56:50.824 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=SchedulerCoordinator02e3aac5-3373-4611-b471-005d255b8291, clientId=AuthServer-bucket-create-response-3, groupId=AuthServer] Setting offset for partition bucket-create-response-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}
21:56:50.868 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.consumer.KafkaMsgConsumer -  
                        consumerRecord.headers. RecordHeaders(headers = [RecordHeader(key = from, value = [77, 105, 110, 105, 111, 83, 101, 114, 118, 101, 114])], isReadOnly = false) 
                        key: MinioServer 
                        value: {"action":"MAKE_BUCKET","value":"okay","createdTime":1704999379267} 
                        partition: 0 
                        topic: bucket-create-response 
                        offset: 11
                    
21:56:50.898 [BucketCreateResponseConsumer-bucket-create-response-3] INFO  [bucketName: ] c.g.s.k.c.BucketCreateResponseConsumer - Consumed message from Topic: bucket-create-response. Message: KafkaMessageTemplate(action=MAKE_BUCKET, value=okay), Thread:BucketCreateResponseConsumer-bucket-create-response-3
